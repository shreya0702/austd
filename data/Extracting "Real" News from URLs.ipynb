{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the \"Real\" News Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read in the three datasets: BBC, Reuters, The Guardian\n",
    "import pandas as pd\n",
    "\n",
    "bbc = pd.DataFrame.from_csv('./ArticlesNewsSitesData/BBC_data.csv',index_col=None)\n",
    "reuters = pd.DataFrame.from_csv('./ArticlesNewsSitesData/Reuter_data.csv',index_col=None)\n",
    "guardian = pd.DataFrame.from_csv('./ArticlesNewsSitesData/TheGuardian_data.csv',index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Annotation Page Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.bbc.co.uk/food/diets/nut_free</td>\n",
       "      <td>Lifestyle_leisure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.bbc.co.uk/food/lamb</td>\n",
       "      <td>Lifestyle_leisure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.bbc.co.uk/food/recipes/baileysandch...</td>\n",
       "      <td>Lifestyle_leisure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.bbc.co.uk/food/recipes/easy_chocola...</td>\n",
       "      <td>Lifestyle_leisure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.bbc.co.uk/food/recipes/fairycakes_8...</td>\n",
       "      <td>Lifestyle_leisure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL Annotation Page Tag\n",
       "0           http://www.bbc.co.uk/food/diets/nut_free   Lifestyle_leisure\n",
       "1                     http://www.bbc.co.uk/food/lamb   Lifestyle_leisure\n",
       "2  http://www.bbc.co.uk/food/recipes/baileysandch...   Lifestyle_leisure\n",
       "3  http://www.bbc.co.uk/food/recipes/easy_chocola...   Lifestyle_leisure\n",
       "4  http://www.bbc.co.uk/food/recipes/fairycakes_8...   Lifestyle_leisure"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://www.theguardian.com/business/2014/jun/06/king-digital-entertainment-ceo-riccardo-zaconni'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guardian['URL'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from newspaper import Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"At the beginning, life and death is every week, and then you have longer cycles,\" says Riccardo Zacconi, chief executive of Britain's most valuable g\n",
      "How King Digital Entertainment's CEO conquered the gaming world\n"
     ]
    }
   ],
   "source": [
    "url = guardian['URL'][0]\n",
    "\n",
    "a = Article(url,language='en')\n",
    "a.download()\n",
    "a.parse()\n",
    "print a.text[:150]\n",
    "print a.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'http://www.theguardian.com'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.fetch_images()\n",
    "a.source_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching article 0...\n",
      "fetching article 20...\n",
      "fetching article 40...\n",
      "fetching article 60...\n",
      "fetching article 80...\n",
      "fetching article 100...\n",
      "fetching article 120...\n",
      "fetching article 140...\n",
      "fetching article 160...\n",
      "fetching article 180...\n",
      "fetching article 200...\n",
      "fetching article 220...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/site-packages/newspaper/parsers.py\", line 54, in fromstring\n",
      "    cls.doc = lxml.html.fromstring(html)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 706, in fromstring\n",
      "    doc = document_fromstring(html, parser=parser, base_url=base_url, **kw)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 600, in document_fromstring\n",
      "    value = etree.fromstring(html, parser, **kw)\n",
      "  File \"lxml.etree.pyx\", line 3032, in lxml.etree.fromstring (src/lxml/lxml.etree.c:68121)\n",
      "  File \"parser.pxi\", line 1786, in lxml.etree._parseMemoryDocument (src/lxml/lxml.etree.c:102470)\n",
      "  File \"parser.pxi\", line 1667, in lxml.etree._parseDoc (src/lxml/lxml.etree.c:101229)\n",
      "  File \"parser.pxi\", line 1035, in lxml.etree._BaseParser._parseUnicodeDoc (src/lxml/lxml.etree.c:96139)\n",
      "  File \"parser.pxi\", line 582, in lxml.etree._ParserContext._handleParseResultDoc (src/lxml/lxml.etree.c:91290)\n",
      "  File \"parser.pxi\", line 683, in lxml.etree._handleParseResult (src/lxml/lxml.etree.c:92476)\n",
      "  File \"parser.pxi\", line 631, in lxml.etree._raiseParseError (src/lxml/lxml.etree.c:91904)\n",
      "XMLSyntaxError: line 240: htmlParseEntityRef: expecting ';'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching article 240...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/site-packages/newspaper/parsers.py\", line 54, in fromstring\n",
      "    cls.doc = lxml.html.fromstring(html)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 706, in fromstring\n",
      "    doc = document_fromstring(html, parser=parser, base_url=base_url, **kw)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 600, in document_fromstring\n",
      "    value = etree.fromstring(html, parser, **kw)\n",
      "  File \"lxml.etree.pyx\", line 3032, in lxml.etree.fromstring (src/lxml/lxml.etree.c:68121)\n",
      "  File \"parser.pxi\", line 1786, in lxml.etree._parseMemoryDocument (src/lxml/lxml.etree.c:102470)\n",
      "  File \"parser.pxi\", line 1667, in lxml.etree._parseDoc (src/lxml/lxml.etree.c:101229)\n",
      "  File \"parser.pxi\", line 1035, in lxml.etree._BaseParser._parseUnicodeDoc (src/lxml/lxml.etree.c:96139)\n",
      "  File \"parser.pxi\", line 582, in lxml.etree._ParserContext._handleParseResultDoc (src/lxml/lxml.etree.c:91290)\n",
      "  File \"parser.pxi\", line 683, in lxml.etree._handleParseResult (src/lxml/lxml.etree.c:92476)\n",
      "  File \"parser.pxi\", line 631, in lxml.etree._raiseParseError (src/lxml/lxml.etree.c:91904)\n",
      "XMLSyntaxError: line 246: htmlParseEntityRef: expecting ';'\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/site-packages/newspaper/parsers.py\", line 54, in fromstring\n",
      "    cls.doc = lxml.html.fromstring(html)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 706, in fromstring\n",
      "    doc = document_fromstring(html, parser=parser, base_url=base_url, **kw)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 600, in document_fromstring\n",
      "    value = etree.fromstring(html, parser, **kw)\n",
      "  File \"lxml.etree.pyx\", line 3032, in lxml.etree.fromstring (src/lxml/lxml.etree.c:68121)\n",
      "  File \"parser.pxi\", line 1786, in lxml.etree._parseMemoryDocument (src/lxml/lxml.etree.c:102470)\n",
      "  File \"parser.pxi\", line 1667, in lxml.etree._parseDoc (src/lxml/lxml.etree.c:101229)\n",
      "  File \"parser.pxi\", line 1035, in lxml.etree._BaseParser._parseUnicodeDoc (src/lxml/lxml.etree.c:96139)\n",
      "  File \"parser.pxi\", line 582, in lxml.etree._ParserContext._handleParseResultDoc (src/lxml/lxml.etree.c:91290)\n",
      "  File \"parser.pxi\", line 683, in lxml.etree._handleParseResult (src/lxml/lxml.etree.c:92476)\n",
      "  File \"parser.pxi\", line 631, in lxml.etree._raiseParseError (src/lxml/lxml.etree.c:91904)\n",
      "XMLSyntaxError: line 239: htmlParseEntityRef: expecting ';'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching article 260...\n",
      "fetching article 280...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/site-packages/newspaper/parsers.py\", line 54, in fromstring\n",
      "    cls.doc = lxml.html.fromstring(html)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 706, in fromstring\n",
      "    doc = document_fromstring(html, parser=parser, base_url=base_url, **kw)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 600, in document_fromstring\n",
      "    value = etree.fromstring(html, parser, **kw)\n",
      "  File \"lxml.etree.pyx\", line 3032, in lxml.etree.fromstring (src/lxml/lxml.etree.c:68121)\n",
      "  File \"parser.pxi\", line 1786, in lxml.etree._parseMemoryDocument (src/lxml/lxml.etree.c:102470)\n",
      "  File \"parser.pxi\", line 1667, in lxml.etree._parseDoc (src/lxml/lxml.etree.c:101229)\n",
      "  File \"parser.pxi\", line 1035, in lxml.etree._BaseParser._parseUnicodeDoc (src/lxml/lxml.etree.c:96139)\n",
      "  File \"parser.pxi\", line 582, in lxml.etree._ParserContext._handleParseResultDoc (src/lxml/lxml.etree.c:91290)\n",
      "  File \"parser.pxi\", line 683, in lxml.etree._handleParseResult (src/lxml/lxml.etree.c:92476)\n",
      "  File \"parser.pxi\", line 631, in lxml.etree._raiseParseError (src/lxml/lxml.etree.c:91904)\n",
      "XMLSyntaxError: line 306: Element script embeds close tag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching article 300...\n",
      "fetching article 320...\n",
      "fetching article 340...\n",
      "fetching article 360...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/site-packages/newspaper/parsers.py\", line 54, in fromstring\n",
      "    cls.doc = lxml.html.fromstring(html)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 706, in fromstring\n",
      "    doc = document_fromstring(html, parser=parser, base_url=base_url, **kw)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 600, in document_fromstring\n",
      "    value = etree.fromstring(html, parser, **kw)\n",
      "  File \"lxml.etree.pyx\", line 3032, in lxml.etree.fromstring (src/lxml/lxml.etree.c:68121)\n",
      "  File \"parser.pxi\", line 1786, in lxml.etree._parseMemoryDocument (src/lxml/lxml.etree.c:102470)\n",
      "  File \"parser.pxi\", line 1667, in lxml.etree._parseDoc (src/lxml/lxml.etree.c:101229)\n",
      "  File \"parser.pxi\", line 1035, in lxml.etree._BaseParser._parseUnicodeDoc (src/lxml/lxml.etree.c:96139)\n",
      "  File \"parser.pxi\", line 582, in lxml.etree._ParserContext._handleParseResultDoc (src/lxml/lxml.etree.c:91290)\n",
      "  File \"parser.pxi\", line 683, in lxml.etree._handleParseResult (src/lxml/lxml.etree.c:92476)\n",
      "  File \"parser.pxi\", line 631, in lxml.etree._raiseParseError (src/lxml/lxml.etree.c:91904)\n",
      "XMLSyntaxError: line 239: htmlParseEntityRef: expecting ';'\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/site-packages/newspaper/parsers.py\", line 54, in fromstring\n",
      "    cls.doc = lxml.html.fromstring(html)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 706, in fromstring\n",
      "    doc = document_fromstring(html, parser=parser, base_url=base_url, **kw)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 600, in document_fromstring\n",
      "    value = etree.fromstring(html, parser, **kw)\n",
      "  File \"lxml.etree.pyx\", line 3032, in lxml.etree.fromstring (src/lxml/lxml.etree.c:68121)\n",
      "  File \"parser.pxi\", line 1786, in lxml.etree._parseMemoryDocument (src/lxml/lxml.etree.c:102470)\n",
      "  File \"parser.pxi\", line 1667, in lxml.etree._parseDoc (src/lxml/lxml.etree.c:101229)\n",
      "  File \"parser.pxi\", line 1035, in lxml.etree._BaseParser._parseUnicodeDoc (src/lxml/lxml.etree.c:96139)\n",
      "  File \"parser.pxi\", line 582, in lxml.etree._ParserContext._handleParseResultDoc (src/lxml/lxml.etree.c:91290)\n",
      "  File \"parser.pxi\", line 683, in lxml.etree._handleParseResult (src/lxml/lxml.etree.c:92476)\n",
      "  File \"parser.pxi\", line 631, in lxml.etree._raiseParseError (src/lxml/lxml.etree.c:91904)\n",
      "XMLSyntaxError: line 239: htmlParseEntityRef: expecting ';'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching article 380...\n",
      "fetching article 400...\n",
      "fetching article 420...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/site-packages/newspaper/parsers.py\", line 54, in fromstring\n",
      "    cls.doc = lxml.html.fromstring(html)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 706, in fromstring\n",
      "    doc = document_fromstring(html, parser=parser, base_url=base_url, **kw)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 600, in document_fromstring\n",
      "    value = etree.fromstring(html, parser, **kw)\n",
      "  File \"lxml.etree.pyx\", line 3032, in lxml.etree.fromstring (src/lxml/lxml.etree.c:68121)\n",
      "  File \"parser.pxi\", line 1786, in lxml.etree._parseMemoryDocument (src/lxml/lxml.etree.c:102470)\n",
      "  File \"parser.pxi\", line 1667, in lxml.etree._parseDoc (src/lxml/lxml.etree.c:101229)\n",
      "  File \"parser.pxi\", line 1035, in lxml.etree._BaseParser._parseUnicodeDoc (src/lxml/lxml.etree.c:96139)\n",
      "  File \"parser.pxi\", line 582, in lxml.etree._ParserContext._handleParseResultDoc (src/lxml/lxml.etree.c:91290)\n",
      "  File \"parser.pxi\", line 683, in lxml.etree._handleParseResult (src/lxml/lxml.etree.c:92476)\n",
      "  File \"parser.pxi\", line 631, in lxml.etree._raiseParseError (src/lxml/lxml.etree.c:91904)\n",
      "XMLSyntaxError: line 1327: Tag footer invalid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching article 440...\n"
     ]
    }
   ],
   "source": [
    "#Features to extract:\n",
    "#text\n",
    "#title\n",
    "#news site\n",
    "#author(s)\n",
    "#image url\n",
    "#published date\n",
    "#language\n",
    "#site url\n",
    "import numpy as np\n",
    "\n",
    "article_data = pd.DataFrame(columns=['text',\"title\", \"website\",\"authors\",\"image_url\", \"published_date\",\\\n",
    "                             \"language\",\"url\"])\n",
    "\n",
    "for i in range(len(bbc.URL)): \n",
    "    if i % 20 == 0:\n",
    "        print 'fetching article %d...' %(i)\n",
    "    try:\n",
    "        a = Article(bbc.URL[i],language='en')\n",
    "        a.download()\n",
    "        a.parse()\n",
    "        a.fetch_images()\n",
    "    \n",
    "        article_data.loc[i] = [a.text,a.title,a.source_url, a.authors, a.top_image, a.publish_date, 'en',bbc.URL[i]]\n",
    "        \n",
    "    except XMLSyntaxError:\n",
    "        print 'article %d not a valid link :/' %(i)\n",
    "        article_data.loc[i] = [None, None, None, 'http://www.bbc.co.uk', None, None, None, 'en', bbc.URL[i] ]\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching article 0...\n",
      "fetching article 20...\n",
      "fetching article 40...\n",
      "fetching article 60...\n",
      "fetching article 80...\n",
      "fetching article 100...\n",
      "fetching article 120...\n",
      "fetching article 140...\n",
      "fetching article 160...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/site-packages/newspaper/parsers.py\", line 54, in fromstring\n",
      "    cls.doc = lxml.html.fromstring(html)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 706, in fromstring\n",
      "    doc = document_fromstring(html, parser=parser, base_url=base_url, **kw)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 600, in document_fromstring\n",
      "    value = etree.fromstring(html, parser, **kw)\n",
      "  File \"lxml.etree.pyx\", line 3032, in lxml.etree.fromstring (src/lxml/lxml.etree.c:68121)\n",
      "  File \"parser.pxi\", line 1786, in lxml.etree._parseMemoryDocument (src/lxml/lxml.etree.c:102470)\n",
      "  File \"parser.pxi\", line 1667, in lxml.etree._parseDoc (src/lxml/lxml.etree.c:101229)\n",
      "  File \"parser.pxi\", line 1035, in lxml.etree._BaseParser._parseUnicodeDoc (src/lxml/lxml.etree.c:96139)\n",
      "  File \"parser.pxi\", line 582, in lxml.etree._ParserContext._handleParseResultDoc (src/lxml/lxml.etree.c:91290)\n",
      "  File \"parser.pxi\", line 683, in lxml.etree._handleParseResult (src/lxml/lxml.etree.c:92476)\n",
      "  File \"parser.pxi\", line 631, in lxml.etree._raiseParseError (src/lxml/lxml.etree.c:91904)\n",
      "XMLSyntaxError: line 1305: ID  already defined\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/site-packages/newspaper/parsers.py\", line 54, in fromstring\n",
      "    cls.doc = lxml.html.fromstring(html)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 706, in fromstring\n",
      "    doc = document_fromstring(html, parser=parser, base_url=base_url, **kw)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 600, in document_fromstring\n",
      "    value = etree.fromstring(html, parser, **kw)\n",
      "  File \"lxml.etree.pyx\", line 3032, in lxml.etree.fromstring (src/lxml/lxml.etree.c:68121)\n",
      "  File \"parser.pxi\", line 1786, in lxml.etree._parseMemoryDocument (src/lxml/lxml.etree.c:102470)\n",
      "  File \"parser.pxi\", line 1667, in lxml.etree._parseDoc (src/lxml/lxml.etree.c:101229)\n",
      "  File \"parser.pxi\", line 1035, in lxml.etree._BaseParser._parseUnicodeDoc (src/lxml/lxml.etree.c:96139)\n",
      "  File \"parser.pxi\", line 582, in lxml.etree._ParserContext._handleParseResultDoc (src/lxml/lxml.etree.c:91290)\n",
      "  File \"parser.pxi\", line 683, in lxml.etree._handleParseResult (src/lxml/lxml.etree.c:92476)\n",
      "  File \"parser.pxi\", line 631, in lxml.etree._raiseParseError (src/lxml/lxml.etree.c:91904)\n",
      "XMLSyntaxError: line 1305: ID  already defined\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/site-packages/newspaper/parsers.py\", line 54, in fromstring\n",
      "    cls.doc = lxml.html.fromstring(html)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 706, in fromstring\n",
      "    doc = document_fromstring(html, parser=parser, base_url=base_url, **kw)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 600, in document_fromstring\n",
      "    value = etree.fromstring(html, parser, **kw)\n",
      "  File \"lxml.etree.pyx\", line 3032, in lxml.etree.fromstring (src/lxml/lxml.etree.c:68121)\n",
      "  File \"parser.pxi\", line 1786, in lxml.etree._parseMemoryDocument (src/lxml/lxml.etree.c:102470)\n",
      "  File \"parser.pxi\", line 1667, in lxml.etree._parseDoc (src/lxml/lxml.etree.c:101229)\n",
      "  File \"parser.pxi\", line 1035, in lxml.etree._BaseParser._parseUnicodeDoc (src/lxml/lxml.etree.c:96139)\n",
      "  File \"parser.pxi\", line 582, in lxml.etree._ParserContext._handleParseResultDoc (src/lxml/lxml.etree.c:91290)\n",
      "  File \"parser.pxi\", line 683, in lxml.etree._handleParseResult (src/lxml/lxml.etree.c:92476)\n",
      "  File \"parser.pxi\", line 631, in lxml.etree._raiseParseError (src/lxml/lxml.etree.c:91904)\n",
      "XMLSyntaxError: line 1305: ID  already defined\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/site-packages/newspaper/parsers.py\", line 54, in fromstring\n",
      "    cls.doc = lxml.html.fromstring(html)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 706, in fromstring\n",
      "    doc = document_fromstring(html, parser=parser, base_url=base_url, **kw)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 600, in document_fromstring\n",
      "    value = etree.fromstring(html, parser, **kw)\n",
      "  File \"lxml.etree.pyx\", line 3032, in lxml.etree.fromstring (src/lxml/lxml.etree.c:68121)\n",
      "  File \"parser.pxi\", line 1786, in lxml.etree._parseMemoryDocument (src/lxml/lxml.etree.c:102470)\n",
      "  File \"parser.pxi\", line 1667, in lxml.etree._parseDoc (src/lxml/lxml.etree.c:101229)\n",
      "  File \"parser.pxi\", line 1035, in lxml.etree._BaseParser._parseUnicodeDoc (src/lxml/lxml.etree.c:96139)\n",
      "  File \"parser.pxi\", line 582, in lxml.etree._ParserContext._handleParseResultDoc (src/lxml/lxml.etree.c:91290)\n",
      "  File \"parser.pxi\", line 683, in lxml.etree._handleParseResult (src/lxml/lxml.etree.c:92476)\n",
      "  File \"parser.pxi\", line 631, in lxml.etree._raiseParseError (src/lxml/lxml.etree.c:91904)\n",
      "XMLSyntaxError: line 1305: ID  already defined\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/site-packages/newspaper/parsers.py\", line 54, in fromstring\n",
      "    cls.doc = lxml.html.fromstring(html)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 706, in fromstring\n",
      "    doc = document_fromstring(html, parser=parser, base_url=base_url, **kw)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 600, in document_fromstring\n",
      "    value = etree.fromstring(html, parser, **kw)\n",
      "  File \"lxml.etree.pyx\", line 3032, in lxml.etree.fromstring (src/lxml/lxml.etree.c:68121)\n",
      "  File \"parser.pxi\", line 1786, in lxml.etree._parseMemoryDocument (src/lxml/lxml.etree.c:102470)\n",
      "  File \"parser.pxi\", line 1667, in lxml.etree._parseDoc (src/lxml/lxml.etree.c:101229)\n",
      "  File \"parser.pxi\", line 1035, in lxml.etree._BaseParser._parseUnicodeDoc (src/lxml/lxml.etree.c:96139)\n",
      "  File \"parser.pxi\", line 582, in lxml.etree._ParserContext._handleParseResultDoc (src/lxml/lxml.etree.c:91290)\n",
      "  File \"parser.pxi\", line 683, in lxml.etree._handleParseResult (src/lxml/lxml.etree.c:92476)\n",
      "  File \"parser.pxi\", line 631, in lxml.etree._raiseParseError (src/lxml/lxml.etree.c:91904)\n",
      "XMLSyntaxError: line 1305: ID  already defined\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/site-packages/newspaper/parsers.py\", line 54, in fromstring\n",
      "    cls.doc = lxml.html.fromstring(html)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 706, in fromstring\n",
      "    doc = document_fromstring(html, parser=parser, base_url=base_url, **kw)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 600, in document_fromstring\n",
      "    value = etree.fromstring(html, parser, **kw)\n",
      "  File \"lxml.etree.pyx\", line 3032, in lxml.etree.fromstring (src/lxml/lxml.etree.c:68121)\n",
      "  File \"parser.pxi\", line 1786, in lxml.etree._parseMemoryDocument (src/lxml/lxml.etree.c:102470)\n",
      "  File \"parser.pxi\", line 1667, in lxml.etree._parseDoc (src/lxml/lxml.etree.c:101229)\n",
      "  File \"parser.pxi\", line 1035, in lxml.etree._BaseParser._parseUnicodeDoc (src/lxml/lxml.etree.c:96139)\n",
      "  File \"parser.pxi\", line 582, in lxml.etree._ParserContext._handleParseResultDoc (src/lxml/lxml.etree.c:91290)\n",
      "  File \"parser.pxi\", line 683, in lxml.etree._handleParseResult (src/lxml/lxml.etree.c:92476)\n",
      "  File \"parser.pxi\", line 631, in lxml.etree._raiseParseError (src/lxml/lxml.etree.c:91904)\n",
      "XMLSyntaxError: line 1305: ID  already defined\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/site-packages/newspaper/parsers.py\", line 54, in fromstring\n",
      "    cls.doc = lxml.html.fromstring(html)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 706, in fromstring\n",
      "    doc = document_fromstring(html, parser=parser, base_url=base_url, **kw)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 600, in document_fromstring\n",
      "    value = etree.fromstring(html, parser, **kw)\n",
      "  File \"lxml.etree.pyx\", line 3032, in lxml.etree.fromstring (src/lxml/lxml.etree.c:68121)\n",
      "  File \"parser.pxi\", line 1786, in lxml.etree._parseMemoryDocument (src/lxml/lxml.etree.c:102470)\n",
      "  File \"parser.pxi\", line 1667, in lxml.etree._parseDoc (src/lxml/lxml.etree.c:101229)\n",
      "  File \"parser.pxi\", line 1035, in lxml.etree._BaseParser._parseUnicodeDoc (src/lxml/lxml.etree.c:96139)\n",
      "  File \"parser.pxi\", line 582, in lxml.etree._ParserContext._handleParseResultDoc (src/lxml/lxml.etree.c:91290)\n",
      "  File \"parser.pxi\", line 683, in lxml.etree._handleParseResult (src/lxml/lxml.etree.c:92476)\n",
      "  File \"parser.pxi\", line 631, in lxml.etree._raiseParseError (src/lxml/lxml.etree.c:91904)\n",
      "XMLSyntaxError: line 1305: ID  already defined\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/site-packages/newspaper/parsers.py\", line 54, in fromstring\n",
      "    cls.doc = lxml.html.fromstring(html)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 706, in fromstring\n",
      "    doc = document_fromstring(html, parser=parser, base_url=base_url, **kw)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 600, in document_fromstring\n",
      "    value = etree.fromstring(html, parser, **kw)\n",
      "  File \"lxml.etree.pyx\", line 3032, in lxml.etree.fromstring (src/lxml/lxml.etree.c:68121)\n",
      "  File \"parser.pxi\", line 1786, in lxml.etree._parseMemoryDocument (src/lxml/lxml.etree.c:102470)\n",
      "  File \"parser.pxi\", line 1667, in lxml.etree._parseDoc (src/lxml/lxml.etree.c:101229)\n",
      "  File \"parser.pxi\", line 1035, in lxml.etree._BaseParser._parseUnicodeDoc (src/lxml/lxml.etree.c:96139)\n",
      "  File \"parser.pxi\", line 582, in lxml.etree._ParserContext._handleParseResultDoc (src/lxml/lxml.etree.c:91290)\n",
      "  File \"parser.pxi\", line 683, in lxml.etree._handleParseResult (src/lxml/lxml.etree.c:92476)\n",
      "  File \"parser.pxi\", line 631, in lxml.etree._raiseParseError (src/lxml/lxml.etree.c:91904)\n",
      "XMLSyntaxError: line 1305: ID  already defined\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/site-packages/newspaper/parsers.py\", line 54, in fromstring\n",
      "    cls.doc = lxml.html.fromstring(html)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 706, in fromstring\n",
      "    doc = document_fromstring(html, parser=parser, base_url=base_url, **kw)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 600, in document_fromstring\n",
      "    value = etree.fromstring(html, parser, **kw)\n",
      "  File \"lxml.etree.pyx\", line 3032, in lxml.etree.fromstring (src/lxml/lxml.etree.c:68121)\n",
      "  File \"parser.pxi\", line 1786, in lxml.etree._parseMemoryDocument (src/lxml/lxml.etree.c:102470)\n",
      "  File \"parser.pxi\", line 1667, in lxml.etree._parseDoc (src/lxml/lxml.etree.c:101229)\n",
      "  File \"parser.pxi\", line 1035, in lxml.etree._BaseParser._parseUnicodeDoc (src/lxml/lxml.etree.c:96139)\n",
      "  File \"parser.pxi\", line 582, in lxml.etree._ParserContext._handleParseResultDoc (src/lxml/lxml.etree.c:91290)\n",
      "  File \"parser.pxi\", line 683, in lxml.etree._handleParseResult (src/lxml/lxml.etree.c:92476)\n",
      "  File \"parser.pxi\", line 631, in lxml.etree._raiseParseError (src/lxml/lxml.etree.c:91904)\n",
      "XMLSyntaxError: line 1305: ID  already defined\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/site-packages/newspaper/parsers.py\", line 54, in fromstring\n",
      "    cls.doc = lxml.html.fromstring(html)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 706, in fromstring\n",
      "    doc = document_fromstring(html, parser=parser, base_url=base_url, **kw)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 600, in document_fromstring\n",
      "    value = etree.fromstring(html, parser, **kw)\n",
      "  File \"lxml.etree.pyx\", line 3032, in lxml.etree.fromstring (src/lxml/lxml.etree.c:68121)\n",
      "  File \"parser.pxi\", line 1786, in lxml.etree._parseMemoryDocument (src/lxml/lxml.etree.c:102470)\n",
      "  File \"parser.pxi\", line 1667, in lxml.etree._parseDoc (src/lxml/lxml.etree.c:101229)\n",
      "  File \"parser.pxi\", line 1035, in lxml.etree._BaseParser._parseUnicodeDoc (src/lxml/lxml.etree.c:96139)\n",
      "  File \"parser.pxi\", line 582, in lxml.etree._ParserContext._handleParseResultDoc (src/lxml/lxml.etree.c:91290)\n",
      "  File \"parser.pxi\", line 683, in lxml.etree._handleParseResult (src/lxml/lxml.etree.c:92476)\n",
      "  File \"parser.pxi\", line 631, in lxml.etree._raiseParseError (src/lxml/lxml.etree.c:91904)\n",
      "XMLSyntaxError: line 1305: ID  already defined\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/site-packages/newspaper/parsers.py\", line 54, in fromstring\n",
      "    cls.doc = lxml.html.fromstring(html)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 706, in fromstring\n",
      "    doc = document_fromstring(html, parser=parser, base_url=base_url, **kw)\n",
      "  File \"/usr/local/lib/python2.7/site-packages/lxml/html/__init__.py\", line 600, in document_fromstring\n",
      "    value = etree.fromstring(html, parser, **kw)\n",
      "  File \"lxml.etree.pyx\", line 3032, in lxml.etree.fromstring (src/lxml/lxml.etree.c:68121)\n",
      "  File \"parser.pxi\", line 1786, in lxml.etree._parseMemoryDocument (src/lxml/lxml.etree.c:102470)\n",
      "  File \"parser.pxi\", line 1667, in lxml.etree._parseDoc (src/lxml/lxml.etree.c:101229)\n",
      "  File \"parser.pxi\", line 1035, in lxml.etree._BaseParser._parseUnicodeDoc (src/lxml/lxml.etree.c:96139)\n",
      "  File \"parser.pxi\", line 582, in lxml.etree._ParserContext._handleParseResultDoc (src/lxml/lxml.etree.c:91290)\n",
      "  File \"parser.pxi\", line 683, in lxml.etree._handleParseResult (src/lxml/lxml.etree.c:92476)\n",
      "  File \"parser.pxi\", line 631, in lxml.etree._raiseParseError (src/lxml/lxml.etree.c:91904)\n",
      "XMLSyntaxError: line 1305: ID  already defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching article 180...\n",
      "fetching article 200...\n",
      "fetching article 220...\n",
      "fetching article 240...\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(reuters.URL)): \n",
    "    if i % 20 == 0:\n",
    "        print 'fetching article %d...' %(i)\n",
    "    try:\n",
    "        a = Article(reuters.URL[i],language='en')\n",
    "        a.download()\n",
    "        a.parse()\n",
    "        a.fetch_images()\n",
    "    \n",
    "        article_data.loc[i + article_data.shape[0]] = [a.text,a.title,a.source_url, a.authors, a.top_image, a.publish_date, 'en',reuters.URL[i]]\n",
    "        \n",
    "    except XMLSyntaxError:\n",
    "        print 'article %d not a valid link :/' %(i)\n",
    "        article_data.loc[i] = [None, None, None, 'http://uk.reuters.com', None, None, None, 'en', reuters.URL[i] ]\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching article 0...\n",
      "fetching article 20...\n",
      "fetching article 40...\n",
      "fetching article 60...\n",
      "fetching article 80...\n",
      "fetching article 100...\n",
      "fetching article 120...\n",
      "fetching article 140...\n",
      "fetching article 160...\n",
      "fetching article 180...\n",
      "fetching article 200...\n",
      "fetching article 220...\n",
      "fetching article 240...\n",
      "fetching article 260...\n",
      "fetching article 280...\n",
      "fetching article 300...\n",
      "fetching article 320...\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(guardian.URL)): \n",
    "    if i % 20 == 0:\n",
    "        print 'fetching article %d...' %(i)\n",
    "    try:\n",
    "        a = Article(guardian.URL[i],language='en')\n",
    "        a.download()\n",
    "        a.parse()\n",
    "        a.fetch_images()\n",
    "    \n",
    "        article_data.loc[i + article_data.shape[0]] = [a.text,a.title,a.source_url, a.authors, a.top_image, a.publish_date, 'en',guardian.URL[i]]\n",
    "        \n",
    "    except XMLSyntaxError:\n",
    "        print 'article %d not a valid link :/' %(i)\n",
    "        article_data.loc[i] = [None, None, None, 'http://www.theguardian.com', None, None, None, 'en', guardian.URL[i] ]\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>website</th>\n",
       "      <th>authors</th>\n",
       "      <th>image_url</th>\n",
       "      <th>published_date</th>\n",
       "      <th>language</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Challenges for a nut-free diet\\n\\nIf you’re co...</td>\n",
       "      <td>Nut-free recipes and information</td>\n",
       "      <td>http://www.bbc.co.uk</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://static.bbci.co.uk/food/1.37.152/assets/...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>en</td>\n",
       "      <td>http://www.bbc.co.uk/food/diets/nut_free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lamb in Britain is called lamb if it’s markete...</td>\n",
       "      <td>Lamb recipes</td>\n",
       "      <td>http://www.bbc.co.uk</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://static.bbci.co.uk/food/1.37.152/assets/...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>en</td>\n",
       "      <td>http://www.bbc.co.uk/food/lamb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This site is optimised for modern web browsers...</td>\n",
       "      <td>Irish cream and chocolate cheesecake</td>\n",
       "      <td>http://www.bbc.co.uk</td>\n",
       "      <td>[Simon Rimmer, Mary Berry, Rob Burns]</td>\n",
       "      <td>http://ichef.bbci.co.uk/food/ic/food_16x9_448/...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>en</td>\n",
       "      <td>http://www.bbc.co.uk/food/recipes/baileysandch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Preheat the oven to 180C/350F/Gas 4. Grease an...</td>\n",
       "      <td>Easy chocolate cake</td>\n",
       "      <td>http://www.bbc.co.uk</td>\n",
       "      <td>[Rachel Manley, James Martin, The Hairy Bikers...</td>\n",
       "      <td>http://ichef.bbci.co.uk/food/ic/food_16x9_448/...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>en</td>\n",
       "      <td>http://www.bbc.co.uk/food/recipes/easy_chocola...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Preheat the oven to 180C/350F/Gas 4 and lin 2 ...</td>\n",
       "      <td>Chocolate fairy cakes</td>\n",
       "      <td>http://www.bbc.co.uk</td>\n",
       "      <td>[Mary Berry, Sarah Brown, Harvey Bertram-brown]</td>\n",
       "      <td>http://ichef.bbci.co.uk/food/ic/food_16x9_448/...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>en</td>\n",
       "      <td>http://www.bbc.co.uk/food/recipes/fairycakes_8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Challenges for a nut-free diet\\n\\nIf you’re co...   \n",
       "1  Lamb in Britain is called lamb if it’s markete...   \n",
       "2  This site is optimised for modern web browsers...   \n",
       "3  Preheat the oven to 180C/350F/Gas 4. Grease an...   \n",
       "4  Preheat the oven to 180C/350F/Gas 4 and lin 2 ...   \n",
       "\n",
       "                                  title               website  \\\n",
       "0      Nut-free recipes and information  http://www.bbc.co.uk   \n",
       "1                          Lamb recipes  http://www.bbc.co.uk   \n",
       "2  Irish cream and chocolate cheesecake  http://www.bbc.co.uk   \n",
       "3                   Easy chocolate cake  http://www.bbc.co.uk   \n",
       "4                 Chocolate fairy cakes  http://www.bbc.co.uk   \n",
       "\n",
       "                                             authors  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2              [Simon Rimmer, Mary Berry, Rob Burns]   \n",
       "3  [Rachel Manley, James Martin, The Hairy Bikers...   \n",
       "4    [Mary Berry, Sarah Brown, Harvey Bertram-brown]   \n",
       "\n",
       "                                           image_url published_date language  \\\n",
       "0  http://static.bbci.co.uk/food/1.37.152/assets/...            NaT       en   \n",
       "1  http://static.bbci.co.uk/food/1.37.152/assets/...            NaT       en   \n",
       "2  http://ichef.bbci.co.uk/food/ic/food_16x9_448/...            NaT       en   \n",
       "3  http://ichef.bbci.co.uk/food/ic/food_16x9_448/...            NaT       en   \n",
       "4  http://ichef.bbci.co.uk/food/ic/food_16x9_448/...            NaT       en   \n",
       "\n",
       "                                                 url  \n",
       "0           http://www.bbc.co.uk/food/diets/nut_free  \n",
       "1                     http://www.bbc.co.uk/food/lamb  \n",
       "2  http://www.bbc.co.uk/food/recipes/baileysandch...  \n",
       "3  http://www.bbc.co.uk/food/recipes/easy_chocola...  \n",
       "4  http://www.bbc.co.uk/food/recipes/fairycakes_8...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.to_csv(article_data,'./real_news_data.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
